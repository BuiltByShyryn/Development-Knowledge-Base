{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82dfea50",
   "metadata": {
    "id": "82dfea50"
   },
   "source": [
    "# Classification Project: EDA → Preprocessing → Train/Test → Model → Threshold → Save/Load\n",
    "\n",
    "Мы используем:\n",
    "- **pandas / numpy**: загрузка, подготовка признаков\n",
    "- **matplotlib / seaborn**: минимальный EDA\n",
    "- **scikit-learn**: `train_test_split`, `Pipeline`, `ColumnTransformer`, `SimpleImputer`, `OneHotEncoder`, `StandardScaler`\n",
    "- **модели**: `LogisticRegression`, `DecisionTreeClassifier`, `RandomForestClassifier`, `GradientBoostingClassifier`\n",
    "- **метрики**: `confusion_matrix`, `precision/recall/F1`, `ROC-AUC`\n",
    "- **CV + GridSearch**: `StratifiedKFold`, `cross_val_score`, `GridSearchCV`\n",
    "- **порог**: 0.5 vs другой\n",
    "- **сохранение**: `joblib.dump` / `joblib.load`\n",
    "\n",
    "## Итог\n",
    "В конце ноутбука вы получите:\n",
    "1) обученную модель в одном объекте `Pipeline`  \n",
    "2) честную оценку на test  \n",
    "3) сохранённую модель `*.joblib`  \n",
    "4) проверку, что загруженная модель предсказывает так же\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73931d36",
   "metadata": {
    "id": "73931d36"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, log_loss\n",
    ")\n",
    "\n",
    "import joblib\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "np.random.seed(42)\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b726b56",
   "metadata": {
    "id": "6b726b56"
   },
   "source": [
    "# 1) Загрузка датасета\n",
    "\n",
    "## Ваш Kaggle CSV\n",
    "1) скачайте `train.csv` (или другой csv)  \n",
    "2) положите рядом с ноутбуком или укажите путь  \n",
    "3) выставьте `TARGET_COL`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32378c0",
   "metadata": {
    "id": "e32378c0"
   },
   "outputs": [],
   "source": [
    "# === Настройте под ваш датасет ===\n",
    "DATA_PATH = \"train.csv\"   # например: \"kaggle_train.csv\"\n",
    "TARGET_COL = None         # например: \"Survived\" или \"Outcome\"\n",
    "ID_COL = None             # например: \"Id\" (если есть и не нужен)\n",
    "\n",
    "df = None\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Loaded CSV:\", DATA_PATH, \"| shape:\", df.shape)\n",
    "except Exception as e:\n",
    "    print(\"Could not read CSV:\", e)\n",
    "    print(\"Falling back to demo dataset...\")\n",
    "\n",
    "if df is None:\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "    data = load_breast_cancer(as_frame=True)\n",
    "    df = data.frame.copy()\n",
    "    df.rename(columns={\"target\": \"target\"}, inplace=True)\n",
    "    TARGET_COL = \"target\"\n",
    "\n",
    "    # Категориальный признак из числового (демо OneHotEncoder)\n",
    "    df[\"radius_bin\"] = pd.qcut(df[\"mean radius\"], q=4, labels=[\"low\", \"mid_low\", \"mid_high\", \"high\"])\n",
    "\n",
    "    # Добавим пропуски (демо SimpleImputer)\n",
    "    df.loc[df.sample(frac=0.06, random_state=42).index, \"mean texture\"] = np.nan\n",
    "    df.loc[df.sample(frac=0.04, random_state=7).index, \"radius_bin\"] = np.nan\n",
    "\n",
    "    print(\"Loaded demo Breast Cancer | shape:\", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f844a0b",
   "metadata": {
    "id": "1f844a0b"
   },
   "source": [
    "# 2) Определяем target и приводим его к формату 0/1\n",
    "\n",
    "Для бинарной классификации target должен быть:\n",
    "- либо 0/1\n",
    "- либо строки/категории, которые можно замапить в 0/1\n",
    "\n",
    "Пример:\n",
    "```python\n",
    "mapping = {\"No\": 0, \"Yes\": 1}\n",
    "df[TARGET_COL] = df[TARGET_COL].map(mapping)\n",
    "```\n",
    "\n",
    "Если target не бинарный (3+ классов), этот шаблон можно адаптировать, но сейчас держим бинарный кейс.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f196b0",
   "metadata": {
    "id": "52f196b0"
   },
   "outputs": [],
   "source": [
    "if TARGET_COL is None:\n",
    "    print(\"⚠️ TARGET_COL = None. Укажите целевую колонку (например, 'Survived').\")\n",
    "else:\n",
    "    print(\"TARGET_COL:\", TARGET_COL)\n",
    "    print(\"Unique target values (first 20):\", df[TARGET_COL].dropna().unique()[:20])\n",
    "    display(df[TARGET_COL].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6dd35f",
   "metadata": {
    "id": "dc6dd35f"
   },
   "source": [
    "# 3) Быстрый обзор таблицы\n",
    "\n",
    "Зачем:\n",
    "- размер и типы\n",
    "- сколько пропусков\n",
    "- пример строк\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbeba54",
   "metadata": {
    "id": "1cbeba54"
   },
   "outputs": [],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "display(df.head(3))\n",
    "\n",
    "print(\"\\nDtypes summary:\")\n",
    "display(df.dtypes.value_counts())\n",
    "\n",
    "print(\"\\nMissing share (top 15):\")\n",
    "na_share = df.isna().mean().sort_values(ascending=False)\n",
    "display(na_share.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef82ce6f",
   "metadata": {
    "id": "ef82ce6f"
   },
   "source": [
    "# 4) Мини-EDA (matplotlib + seaborn)\n",
    "\n",
    "Обязательный минимум:\n",
    "1) баланс классов  \n",
    "2) распределение 1 числового признака по классам  \n",
    "3) countplot 1 категориального признака (если есть)  \n",
    "4) корреляции числовых с target (если target 0/1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc7e2d",
   "metadata": {
    "id": "86bc7e2d"
   },
   "outputs": [],
   "source": [
    "assert TARGET_COL in df.columns, \"Проверьте TARGET_COL — он должен быть в df.columns\"\n",
    "\n",
    "# 4.1) Баланс классов\n",
    "plt.figure(figsize=(5,3))\n",
    "df[TARGET_COL].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Target class counts\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(True, axis=\"y\")\n",
    "plt.show()\n",
    "\n",
    "# 4.2) Выберем один числовой признак и нарисуем распределение по классам\n",
    "num_cols = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "num_cols = [c for c in num_cols if c != TARGET_COL]\n",
    "\n",
    "if len(num_cols) > 0:\n",
    "    col = num_cols[0]\n",
    "    plt.figure(figsize=(7,4))\n",
    "    for t in sorted(df[TARGET_COL].dropna().unique())[:2]:\n",
    "        subset = df[df[TARGET_COL] == t][col].dropna()\n",
    "        plt.hist(subset, bins=25, alpha=0.5, label=f\"target={t}\")\n",
    "    plt.title(f\"Feature distribution by class: {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numeric columns found.\")\n",
    "\n",
    "# 4.3) Если есть категориальные — countplot\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "cat_cols = [c for c in cat_cols if c != TARGET_COL]\n",
    "\n",
    "if len(cat_cols) > 0:\n",
    "    c = cat_cols[0]\n",
    "    plt.figure(figsize=(8,3))\n",
    "    sns.countplot(data=df, x=c, hue=TARGET_COL)\n",
    "    plt.title(f\"Count plot: {c} by target\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.grid(True, axis=\"y\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No categorical columns found (or only target).\")\n",
    "\n",
    "# 4.4) Корреляции числовых признаков с target\n",
    "if len(num_cols) > 0 and df[TARGET_COL].dropna().nunique() <= 2:\n",
    "    corr = df[num_cols + [TARGET_COL]].corr(numeric_only=True)[TARGET_COL].drop(TARGET_COL)\n",
    "    top = corr.abs().sort_values(ascending=False).head(10)\n",
    "    display(pd.DataFrame({\"corr\": corr.loc[top.index], \"abs_corr\": top.values}).sort_values(\"abs_corr\", ascending=False))\n",
    "\n",
    "    cols_hm = top.index.tolist() + [TARGET_COL]\n",
    "    plt.figure(figsize=(9,6))\n",
    "    sns.heatmap(df[cols_hm].corr(numeric_only=True), annot=False)\n",
    "    plt.title(\"Correlation heatmap (top numeric + target)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e5d35",
   "metadata": {
    "id": "bd9e5d35"
   },
   "source": [
    "# 5) Формируем X/y и делаем train/test split\n",
    "\n",
    "Правила:\n",
    "- `y` = target\n",
    "- `X` = все остальные признаки\n",
    "- id-колонку убрать (если есть)\n",
    "- `stratify=y` для похожего баланса классов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7c9d8",
   "metadata": {
    "id": "87b7c9d8"
   },
   "outputs": [],
   "source": [
    "df_work = df.copy()\n",
    "\n",
    "if ID_COL is not None and ID_COL in df_work.columns:\n",
    "    df_work = df_work.drop(columns=[ID_COL])\n",
    "    print(\"Dropped ID_COL:\", ID_COL)\n",
    "\n",
    "# Убираем строки без target\n",
    "df_work = df_work.dropna(subset=[TARGET_COL]).copy()\n",
    "\n",
    "X = df_work.drop(columns=[TARGET_COL])\n",
    "y = df_work[TARGET_COL]\n",
    "\n",
    "# Если target не 0/1, замапьте его ДО split!\n",
    "# y = y.map({\"No\":0, \"Yes\":1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
    "print(\"Train share:\", y_train.value_counts(normalize=True).to_dict())\n",
    "print(\"Test  share:\", y_test.value_counts(normalize=True).to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7447ebd9",
   "metadata": {
    "id": "7447ebd9"
   },
   "source": [
    "# 6) Preprocessing через Pipeline + ColumnTransformer\n",
    "\n",
    "Универсальный шаблон для Kaggle:\n",
    "- **числовые**: медиана + StandardScaler (полезно для логрег)\n",
    "- **категориальные**: most_frequent + OneHotEncoder\n",
    "\n",
    "Деревьям scaler не нужен, но он не мешает, потому что лес/бустинг увидят уже числовой one-hot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6871b",
   "metadata": {
    "id": "e8c6871b"
   },
   "outputs": [],
   "source": [
    "cat_features = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_features = [c for c in X_train.columns if c not in cat_features]\n",
    "\n",
    "print(\"Numeric features:\", len(num_features))\n",
    "print(\"Categorical features:\", len(cat_features))\n",
    "print(\"Example cat:\", cat_features[:5])\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_features),\n",
    "    (\"cat\", cat_pipe, cat_features),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303aa81a",
   "metadata": {
    "id": "303aa81a"
   },
   "source": [
    "## Метрики и порог\n",
    "\n",
    "- `predict_proba` → вероятности класса 1  \n",
    "- порог 0.5 vs другой: управляем precision/recall\n",
    "- `log_loss` оценивает качество вероятностей (уверенности)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb81eb",
   "metadata": {
    "id": "fdcb81eb"
   },
   "outputs": [],
   "source": [
    "def metrics_at_threshold(y_true, p1, thr=0.5):\n",
    "    y_pred = (p1 >= thr).astype(int)\n",
    "    return {\n",
    "        \"threshold\": thr,\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_true, p1),\n",
    "        \"logloss\": log_loss(y_true, p1),\n",
    "    }, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f2c082",
   "metadata": {
    "id": "c9f2c082"
   },
   "source": [
    "# 7) Baseline: LogisticRegression\n",
    "\n",
    "Быстро обучается, даёт вероятности — отличный baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc7716",
   "metadata": {
    "id": "73dc7716"
   },
   "outputs": [],
   "source": [
    "lr_model = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=3000))\n",
    "])\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "proba_test = lr_model.predict_proba(X_test)[:, 1]\n",
    "m05, y_pred_05 = metrics_at_threshold(y_test.values, proba_test, thr=0.5)\n",
    "\n",
    "print(\"LogReg metrics @0.5:\", m05)\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred_05))\n",
    "print(\"\\nReport:\\n\", classification_report(y_test, y_pred_05, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10609f0",
   "metadata": {
    "id": "a10609f0"
   },
   "source": [
    "## 7.1) Пороговая таблица (0.5 vs другие)\n",
    "\n",
    "Смотрим, как меняются precision/recall/F1 при разных порогах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae6b4f",
   "metadata": {
    "id": "45ae6b4f"
   },
   "outputs": [],
   "source": [
    "thresholds = [0.2, 0.35, 0.5, 0.65, 0.8]\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    m, _ = metrics_at_threshold(y_test.values, proba_test, thr=t)\n",
    "    rows.append(m)\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a49509c",
   "metadata": {
    "id": "7a49509c"
   },
   "source": [
    "## 7.2) ROC curve\n",
    "\n",
    "ROC-AUC показывает качество по всем порогам сразу.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686c0c2",
   "metadata": {
    "id": "8686c0c2"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thr = roc_curve(y_test, proba_test)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC curve — LogisticRegression\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df666b15",
   "metadata": {
    "id": "df666b15"
   },
   "source": [
    "# 8) CV сравнение моделей (Tree / RF / Boosting)\n",
    "\n",
    "Оценка: **F1** (часто лучше, чем accuracy при дисбалансе).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735349b1",
   "metadata": {
    "id": "735349b1"
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": Pipeline([(\"preprocess\", preprocess), (\"model\", LogisticRegression(max_iter=3000))]),\n",
    "    \"Tree\": Pipeline([(\"preprocess\", preprocess), (\"model\", DecisionTreeClassifier(random_state=42))]),\n",
    "    \"RF\": Pipeline([(\"preprocess\", preprocess), (\"model\", RandomForestClassifier(\n",
    "        n_estimators=400, min_samples_leaf=2, random_state=42, n_jobs=-1\n",
    "    ))]),\n",
    "    \"GB\": Pipeline([(\"preprocess\", preprocess), (\"model\", GradientBoostingClassifier(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=3, random_state=42\n",
    "    ))]),\n",
    "}\n",
    "\n",
    "# Опционально: XGBoost, если установлен\n",
    "xgb_ok = True\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except Exception:\n",
    "    xgb_ok = False\n",
    "\n",
    "if xgb_ok:\n",
    "    models[\"XGB\"] = Pipeline([(\"preprocess\", preprocess), (\"model\", XGBClassifier(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=4,\n",
    "        subsample=0.9, colsample_bytree=0.9,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42, n_jobs=-1\n",
    "    ))])\n",
    "\n",
    "rows = []\n",
    "for name, m in models.items():\n",
    "    scores = cross_val_score(m, X_train, y_train, cv=cv, scoring=\"f1\")\n",
    "    rows.append({\"model\": name, \"cv_f1_mean\": scores.mean(), \"cv_f1_std\": scores.std()})\n",
    "    print(f\"{name:6s} | mean={scores.mean():.4f} std={scores.std():.4f} | scores={np.round(scores,4)}\")\n",
    "\n",
    "cv_table = pd.DataFrame(rows).sort_values(\"cv_f1_mean\", ascending=False)\n",
    "cv_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdbd387",
   "metadata": {
    "id": "cbdbd387"
   },
   "source": [
    "# 9) GridSearchCV для кандидата (минимально)\n",
    "\n",
    "Выбираем модель-кандидат и тюним 2–3 параметра маленькой сеткой.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2248c5f8",
   "metadata": {
    "id": "2248c5f8"
   },
   "outputs": [],
   "source": [
    "best_name = cv_table.iloc[0][\"model\"]\n",
    "print(\"Best by CV (mean F1):\", best_name)\n",
    "\n",
    "# Часто удобно тюнить RF как старт\n",
    "CANDIDATE = \"RF\" if \"RF\" in models else best_name\n",
    "print(\"Candidate for GridSearch:\", CANDIDATE)\n",
    "\n",
    "candidate_pipe = models[CANDIDATE]\n",
    "\n",
    "if CANDIDATE == \"RF\":\n",
    "    param_grid = {\n",
    "        \"model__n_estimators\": [200, 500],\n",
    "        \"model__max_depth\": [None, 4, 6],\n",
    "        \"model__min_samples_leaf\": [1, 2, 5],\n",
    "    }\n",
    "elif CANDIDATE == \"GB\":\n",
    "    param_grid = {\n",
    "        \"model__n_estimators\": [100, 300, 600],\n",
    "        \"model__learning_rate\": [0.03, 0.05, 0.1],\n",
    "        \"model__max_depth\": [2, 3, 4],\n",
    "    }\n",
    "elif CANDIDATE == \"Tree\":\n",
    "    param_grid = {\n",
    "        \"model__max_depth\": [2, 3, 4, 5, None],\n",
    "        \"model__min_samples_leaf\": [1, 2, 5, 10],\n",
    "    }\n",
    "elif CANDIDATE == \"LogReg\":\n",
    "    param_grid = {\"model__C\": [0.1, 1.0, 3.0, 10.0]}\n",
    "elif CANDIDATE == \"XGB\":\n",
    "    param_grid = {\n",
    "        \"model__max_depth\": [3, 4, 5],\n",
    "        \"model__n_estimators\": [300, 600],\n",
    "        \"model__learning_rate\": [0.03, 0.05, 0.1],\n",
    "    }\n",
    "else:\n",
    "    param_grid = {}\n",
    "\n",
    "gs = GridSearchCV(candidate_pipe, param_grid=param_grid, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", gs.best_params_)\n",
    "print(\"Best CV F1 :\", gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff820bb",
   "metadata": {
    "id": "7ff820bb"
   },
   "source": [
    "# 10) Финальная модель → test → порог → save/load\n",
    "\n",
    "Правильная логика:\n",
    "- подбираем параметры на **train** через CV\n",
    "- test используем **1 раз** для честной оценки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3491d",
   "metadata": {
    "id": "dff3491d"
   },
   "outputs": [],
   "source": [
    "best_model = gs.best_estimator_\n",
    "print(\"Final model:\", best_model)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "m05, y_pred_05 = metrics_at_threshold(y_test.values, proba_test, thr=0.5)\n",
    "\n",
    "print(\"Metrics @0.5:\", m05)\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred_05))\n",
    "print(\"\\nReport:\\n\", classification_report(y_test, y_pred_05, digits=4))\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thr = roc_curve(y_test, proba_test)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC curve — Final model\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Пороговая таблица\n",
    "thresholds = [0.2, 0.35, 0.5, 0.65, 0.8]\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    m, _ = metrics_at_threshold(y_test.values, proba_test, thr=t)\n",
    "    rows.append(m)\n",
    "display(pd.DataFrame(rows))\n",
    "\n",
    "# Подбор порога по F1 (демо: на test — для понимания, в проекте делайте на val)\n",
    "grid = np.linspace(0.05, 0.95, 91)\n",
    "best_thr, best_f1 = None, -1\n",
    "for t in grid:\n",
    "    m, _ = metrics_at_threshold(y_test.values, proba_test, thr=float(t))\n",
    "    if m[\"f1\"] > best_f1:\n",
    "        best_f1 = m[\"f1\"]\n",
    "        best_thr = t\n",
    "print(\"Best threshold by F1 (demo):\", best_thr, \"F1:\", best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3478f1",
   "metadata": {
    "id": "5c3478f1"
   },
   "source": [
    "## 10.1) Просмотр параметров (get_params)\n",
    "\n",
    "Полезно, чтобы увидеть, что реально внутри Pipeline, и какие гиперпараметры применились.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4242ccc3",
   "metadata": {
    "id": "4242ccc3"
   },
   "outputs": [],
   "source": [
    "params = best_model.get_params()\n",
    "model_keys = sorted([k for k in params.keys() if k.startswith(\"model__\")])\n",
    "\n",
    "print(\"Some model__ params:\")\n",
    "for k in model_keys[:40]:\n",
    "    print(k, \"=\", params[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be4f997",
   "metadata": {
    "id": "9be4f997"
   },
   "source": [
    "## 10.2) Сохранение и загрузка модели\n",
    "\n",
    "Сохраняем **весь Pipeline** (preprocess + модель) — это удобно и безопасно.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e9d0f",
   "metadata": {
    "id": "651e9d0f"
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = \"classification_model.joblib\"\n",
    "joblib.dump(best_model, MODEL_PATH)\n",
    "print(\"Saved model to:\", MODEL_PATH)\n",
    "\n",
    "loaded_model = joblib.load(MODEL_PATH)\n",
    "print(\"Loaded model type:\", type(loaded_model))\n",
    "\n",
    "# Проверим, что предсказания совпадают на первых 5 строках test\n",
    "p1 = best_model.predict_proba(X_test.head(5))[:, 1]\n",
    "p2 = loaded_model.predict_proba(X_test.head(5))[:, 1]\n",
    "print(\"proba original:\", np.round(p1, 4))\n",
    "print(\"proba loaded  :\", np.round(p2, 4))\n",
    "\n",
    "pred_loaded = (p2 >= 0.5).astype(int)\n",
    "print(\"pred_loaded:\", pred_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6224e304",
   "metadata": {
    "id": "6224e304"
   },
   "source": [
    "# 11) Как адаптировать под Kaggle (чек-лист)\n",
    "\n",
    "1) Укажите `DATA_PATH`, `TARGET_COL` (и при необходимости `ID_COL`)  \n",
    "2) Если target не 0/1 → сделайте `map` в 0/1  \n",
    "3) Обзор: `df.head()`, `df.dtypes`, `df.isna().mean()`  \n",
    "4) Мини-EDA: баланс классов, пропуски, 1–2 графика  \n",
    "5) `train_test_split(..., stratify=y)`  \n",
    "6) `preprocess` (num/cat) через ColumnTransformer  \n",
    "7) Baseline LogisticRegression (с вероятностями)  \n",
    "8) CV сравнение моделей (F1)  \n",
    "9) GridSearch для кандидата  \n",
    "10) Финальная оценка на test + ROC + пороги  \n",
    "11) `joblib.dump` и проверка `joblib.load`  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
